{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bef2c2-544c-4513-b7aa-6061dbb465f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.5.1+cpu)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.20.1+cpu)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.12/site-packages (2.0.37)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.12/site-packages (2.9.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision tqdm numpy pandas sqlalchemy\n",
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea724125-6b4d-44ff-b2f7-f468c9c640a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89095af6-f5c4-4c29-ab85-45c1e8fafee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    'postgresql://rg5073:rg5073pass@129.114.27.3:5432/cleaned_meta_data_db',\n",
    "    pool_size=10,\n",
    "    max_overflow=0,\n",
    "    pool_timeout=30,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c317ddb9-15bc-4bdc-a6f8-82f33c1c6a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data:\n",
      "      paper_id chunk_no       chunk_id     txt_filename  \\\n",
      "0  0704.0107v1     None  0704.0107v1_5  0704.0107v1.txt   \n",
      "1  0704.0107v1     None  0704.0107v1_6  0704.0107v1.txt   \n",
      "2  0704.0107v1     None  0704.0107v1_7  0704.0107v1.txt   \n",
      "3  0704.0674v2     None  0704.0674v2_1  0704.0674v2.txt   \n",
      "4  0704.0674v2     None  0704.0674v2_2  0704.0674v2.txt   \n",
      "\n",
      "                                               query  \\\n",
      "0  [\"What is the Parzen's estimator formula used ...   \n",
      "1  [\"How to adapt the model Eq. 19 to experimenta...   \n",
      "2  [\"What is the effect of increasing T on the mo...   \n",
      "3  [\"Galaxy alignment types\", \"Galaxy group catal...   \n",
      "4  [\"What are the preferential distributions of s...   \n",
      "\n",
      "                                          chunk_data  \n",
      "0  lim N 1 N N X x qi, , which we consider as the...  \n",
      "1  model relative to experimentally estimated fT ...  \n",
      "2  a new term with the parameters xT , , x g x xT...  \n",
      "3  arXiv 0704.0674v2 astro ph 8 Jun 2007 Draft ve...  \n",
      "4  neous samples. This has resulted in robust det...  \n"
     ]
    }
   ],
   "source": [
    "query_preview = \"SELECT * FROM arxiv_chunks_training_4_phrases1 LIMIT 5;\"\n",
    "preview = pd.read_sql(query_preview, engine)\n",
    "print(\" Data:\")\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cbed54-7b82-42a0-b6d4-a6fe2f44182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks with exactly 3 queries: 6043\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM arxiv_chunks_training_4_phrases1;\"))\n",
    "    count = result.scalar()\n",
    "    print(f\"Num of records: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9b7059-ce4a-42a7-b859-23f31194be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     column_name data_type\n",
      "0       chunk_no   integer\n",
      "1       chunk_id      text\n",
      "2       paper_id      text\n",
      "3          query      text\n",
      "4     chunk_data      text\n",
      "5  query_phrases      text\n",
      "6   txt_filename      text\n"
     ]
    }
   ],
   "source": [
    "inspect_query = \"\"\"\n",
    "SELECT column_name, data_type\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = 'arxiv_chunks_training_4_phrases1'\n",
    "\"\"\"\n",
    "df_schema = pd.read_sql(inspect_query, engine)\n",
    "print(df_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "912a2835-3862-4295-aa81-897c8603379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"ALTER TABLE arxiv_chunks_training_4_phrases1 ADD COLUMN query_phrases TEXT;\"))\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090ccb15-f4a5-45b7-85c3-55424f577b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q keybert sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88791930-ccc0-474c-a861-0bb2d754afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbdc862f-189c-4c77-8d20-eb44fdd085cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT chunk_id, query\n",
    "FROM arxiv_chunks_training_4_phrases1\n",
    "WHERE query IS NOT NULL AND query <> ''\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "df['query_list'] = df['query'].apply(json.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15f18ac2-525a-45de-b88c-cd2d3056834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated batch 0 to 100\n",
      "Updated batch 100 to 200\n",
      "Updated batch 200 to 300\n",
      "Updated batch 300 to 400\n",
      "Updated batch 400 to 500\n",
      "Updated batch 500 to 600\n",
      "Updated batch 600 to 700\n",
      "Updated batch 700 to 800\n",
      "Updated batch 800 to 900\n",
      "Updated batch 900 to 1000\n",
      "Updated batch 1000 to 1100\n",
      "Updated batch 1100 to 1200\n",
      "Updated batch 1200 to 1300\n",
      "Updated batch 1300 to 1400\n",
      "Updated batch 1400 to 1500\n",
      "Updated batch 1500 to 1600\n",
      "Updated batch 1600 to 1700\n",
      "Updated batch 1700 to 1800\n",
      "Updated batch 1800 to 1900\n",
      "Updated batch 1900 to 2000\n",
      "Updated batch 2000 to 2100\n",
      "Updated batch 2100 to 2200\n",
      "Updated batch 2200 to 2300\n",
      "Updated batch 2300 to 2400\n",
      "Updated batch 2400 to 2500\n",
      "Updated batch 2500 to 2600\n",
      "Updated batch 2600 to 2700\n",
      "Updated batch 2700 to 2800\n",
      "Updated batch 2800 to 2900\n",
      "Updated batch 2900 to 3000\n",
      "Updated batch 3000 to 3100\n",
      "Updated batch 3100 to 3200\n",
      "Updated batch 3200 to 3300\n",
      "Updated batch 3300 to 3400\n",
      "Updated batch 3400 to 3500\n",
      "Updated batch 3500 to 3600\n",
      "Updated batch 3600 to 3700\n",
      "Updated batch 3700 to 3800\n",
      "Updated batch 3800 to 3900\n",
      "Updated batch 3900 to 4000\n",
      "Updated batch 4000 to 4100\n",
      "Updated batch 4100 to 4200\n",
      "Updated batch 4200 to 4300\n",
      "Updated batch 4300 to 4400\n",
      "Updated batch 4400 to 4500\n",
      "Updated batch 4500 to 4600\n",
      "Updated batch 4600 to 4700\n",
      "Updated batch 4700 to 4800\n",
      "Updated batch 4800 to 4900\n",
      "Updated batch 4900 to 5000\n",
      "Updated batch 5000 to 5100\n",
      "Updated batch 5100 to 5200\n",
      "Updated batch 5200 to 5300\n",
      "Updated batch 5300 to 5400\n",
      "Updated batch 5400 to 5500\n",
      "Updated batch 5500 to 5600\n",
      "Updated batch 5600 to 5700\n",
      "Updated batch 5700 to 5800\n",
      "Updated batch 5800 to 5900\n",
      "Updated batch 5900 to 6000\n",
      "Updated batch 6000 to 6043\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "import time\n",
    "\n",
    "batch_size = 100\n",
    "rows = df.to_dict(orient=\"records\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for i in range(0, len(rows), batch_size):\n",
    "        batch = rows[i:i + batch_size]\n",
    "        for row in batch:\n",
    "            update_stmt = text(\"\"\"\n",
    "                UPDATE arxiv_chunks_training_4_phrases1\n",
    "                SET query_phrases = :phrases\n",
    "                WHERE chunk_id = :chunk_id\n",
    "            \"\"\")\n",
    "            conn.execute(update_stmt, {\n",
    "                'phrases': json.dumps(row['query_phrases']),\n",
    "                'chunk_id': row['chunk_id']\n",
    "            })\n",
    "        print(f\"Updated batch {i} to {i + len(batch)}\")\n",
    "        time.sleep(0.1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "850ae21f-e4f5-4d0c-9224-6641cdc33bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data:\n",
      "      paper_id chunk_no        chunk_id     txt_filename  \\\n",
      "0  0704.0107v1     None   0704.0107v1_5  0704.0107v1.txt   \n",
      "1  0704.0107v1     None   0704.0107v1_6  0704.0107v1.txt   \n",
      "2  0704.0076v2     None  0704.0076v2_12  0704.0076v2.txt   \n",
      "3  0704.0107v1     None   0704.0107v1_7  0704.0107v1.txt   \n",
      "4  0704.0674v2     None   0704.0674v2_1  0704.0674v2.txt   \n",
      "\n",
      "                                               query  \\\n",
      "0  [\"What is the Parzen's estimator formula used ...   \n",
      "1  [\"How to adapt the model Eq. 19 to experimenta...   \n",
      "2  [\"CP asymmetry\", \"Amplitude C and T\", \"SU rela...   \n",
      "3  [\"What is the effect of increasing T on the mo...   \n",
      "4  [\"Galaxy alignment types\", \"Galaxy group catal...   \n",
      "\n",
      "                                          chunk_data  \\\n",
      "0  lim N 1 N N X x qi, , which we consider as the...   \n",
      "1  model relative to experimentally estimated fT ...   \n",
      "2  the CP asymmetry sum rule predicts ACP B0 K0 0...   \n",
      "3  a new term with the parameters xT , , x g x xT...   \n",
      "4  arXiv 0704.0674v2 astro ph 8 Jun 2007 Draft ve...   \n",
      "\n",
      "                                       query_phrases  \n",
      "0  [\"parzen estimator formula\", \"redundancy numbe...  \n",
      "1  [\"adapt model eq\", \"growing pruning methods\", ...  \n",
      "2       [\"cp asymmetry\", \"amplitude\", \"su relation\"]  \n",
      "3  [\"pdf new experimental\", \"annihilation process...  \n",
      "4  [\"galaxy alignment types\", \"galaxy group catal...  \n"
     ]
    }
   ],
   "source": [
    "query_preview = \"SELECT * FROM arxiv_chunks_training_4_phrases1 LIMIT 5;\"\n",
    "preview = pd.read_sql(query_preview, engine)\n",
    "print(\" Data:\")\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a865dd53-1321-4142-ac89-178335433f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_dict = dict(zip(df['chunk_id'], df['query_phrases']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6abd90f1-2b3e-4ac1-af3b-6de3809de7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"query_phrases_by_chunk.json\", \"w\") as f:\n",
    "    json.dump(phrases_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6aad4-b6d2-4302-9f6f-f8c997ad081d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
