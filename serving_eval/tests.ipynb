{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & config\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Your Postgres connection\n",
    "DB_URL     = \"postgresql+psycopg2://rg5073:rg5073pass@129.114.27.112:5432/cleaned_meta_data_db\"\n",
    "TABLE_NAME = \"arxiv_chunks_eval_5\"\n",
    "EVAL_DIR   = \"/home/pb/projects/course/sem2/mlops/project/mlops/Neura-Scholar/serving_eval/eval\"        # where heldout.jsonl etc live\n",
    "TOP_K      = 10            # how many papers to return & evaluate\n",
    "\n",
    "# The embedding columns you’ve stored, e.g.:\n",
    "MODEL_DETAILS = [\n",
    "    {\n",
    "        \"column\": \"chunk_embedding_768\",\n",
    "        \"model_path\": \"/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert.onnx\",\n",
    "    },\n",
    "    {\n",
    "        \"column\": \"chunk_embedding_768_dyn\",\n",
    "        \"model_path\": \"/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_dyn.onnx\",\n",
    "    },\n",
    "    {\n",
    "        \"column\": \"chunk_embedding_768_graph\",\n",
    "        \"model_path\": \"/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_opt.onnx\",\n",
    "    },\n",
    "    {\n",
    "        \"column\": \"chunk_embedding_768_static_h\",\n",
    "        \"model_path\": \"/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_static_heavy.onnx\",\n",
    "    },\n",
    "    {\n",
    "        \"column\": \"chunk_embedding_768_static_m\",\n",
    "        \"model_path\": \"/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_static_moderate.onnx\",\n",
    "    },\n",
    "]\n",
    "\n",
    "engine = create_engine(DB_URL, pool_timeout=30, max_overflow=0)\n",
    "os.makedirs(\"indexes\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8feb36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load your eval test records once\n",
    "heldout = [json.loads(l) for l in open(f\"{EVAL_DIR}/heldout.jsonl\")]\n",
    "slices  = [json.loads(l) for l in open(f\"{EVAL_DIR}/slices.jsonl\")]\n",
    "perturbs= [json.loads(l) for l in open(f\"{EVAL_DIR}/perturbations.jsonl\")]\n",
    "failures=[json.loads(l) for l in open(f\"{EVAL_DIR}/failures.jsonl\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa2e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper to compute Recall@K and MRR@K\n",
    "def recall_at_k(gt, pred, k=TOP_K):\n",
    "    return int(any(p in gt for p in pred[:k]))\n",
    "\n",
    "def mrr_at_k(gt, pred, k=TOP_K):\n",
    "    for rank, p in enumerate(pred[:k], start=1):\n",
    "        if p in gt:\n",
    "            return 1.0/rank\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87165860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:16:48 INFO === Evaluating `chunk_embedding_768` with ONNX [/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert.onnx] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:16:48 INFO Loaded index `indexes/chunk_embedding_768.index` in 0.16s\n",
      "\u001b[0;93m2025-05-12 13:16:49.651647720 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 6 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "13:16:50 INFO Loaded ONNX session + tokenizer in 0.60s\n",
      "13:16:51 WARNING Embedding mismatch for `chunk_embedding_768` (cos = 0.722) – skipping this model.\n",
      "13:16:51 INFO === Evaluating `chunk_embedding_768_dyn` with ONNX [/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_dyn.onnx] ===\n",
      "13:16:51 INFO Loaded index `indexes/chunk_embedding_768_dyn.index` in 0.15s\n",
      "\u001b[0;93m2025-05-12 13:16:51.678536524 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 90 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "13:16:51 INFO Loaded ONNX session + tokenizer in 0.22s\n",
      "13:16:52 INFO Embedding sanity‑check passed (cos = 0.951)\n",
      "13:18:20 INFO → Held‑out Recall@10 (raw|adj|chunk) = 0.2235 | 0.5167 | 1.2475 ,  MRR@10 = 0.1855\n",
      "13:20:14 INFO → Slice count: 403\n",
      "13:21:17 INFO → Perturbation pass rate 0.1550\n",
      "13:21:18 INFO → Failure‑mode pass rate 0.2581\n",
      "13:21:18 INFO === Evaluating `chunk_embedding_768_graph` with ONNX [/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_opt.onnx] ===\n",
      "13:21:19 INFO Loaded index `indexes/chunk_embedding_768_graph.index` in 0.11s\n",
      "\u001b[0;93m2025-05-12 13:21:19.444587437 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 6 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "13:21:19 INFO Loaded ONNX session + tokenizer in 0.63s\n",
      "13:21:20 INFO Embedding sanity‑check passed (cos = 0.977)\n",
      "13:21:35 INFO → Held‑out Recall@10 (raw|adj|chunk) = 0.2491 | 0.5779 | 1.3178 ,  MRR@10 = 0.2149\n",
      "13:21:52 INFO → Slice count: 403\n",
      "13:21:55 INFO → Perturbation pass rate 0.1900\n",
      "13:21:56 INFO → Failure‑mode pass rate 0.4194\n",
      "13:21:56 INFO === Evaluating `chunk_embedding_768_static_h` with ONNX [/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_static_heavy.onnx] ===\n",
      "13:21:56 INFO Loaded index `indexes/chunk_embedding_768_static_h.index` in 0.09s\n",
      "\u001b[0;93m2025-05-12 13:21:56.490732037 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 88 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "13:21:56 INFO Loaded ONNX session + tokenizer in 0.20s\n",
      "13:21:57 WARNING Embedding mismatch for `chunk_embedding_768_static_h` (cos = 0.193) – skipping this model.\n",
      "13:21:57 INFO === Evaluating `chunk_embedding_768_static_m` with ONNX [/home/pb/projects/course/sem2/mlops/project/mlops/models/distilbert_static_moderate.onnx] ===\n",
      "13:21:57 INFO Loaded index `indexes/chunk_embedding_768_static_m.index` in 0.03s\n",
      "\u001b[0;93m2025-05-12 13:21:57.483462787 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 25 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "13:21:57 INFO Loaded ONNX session + tokenizer in 0.28s\n",
      "13:21:57 WARNING Embedding mismatch for `chunk_embedding_768_static_m` (cos = 0.210) – skipping this model.\n",
      "13:21:57 INFO Done! Results written to eval/model_comparison.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>recall@10_raw</th>\n",
       "      <th>recall@10_adj</th>\n",
       "      <th>chunk_recall</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>slice_recalls</th>\n",
       "      <th>perturb_acc</th>\n",
       "      <th>failure_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk_embedding_768_dyn</td>\n",
       "      <td>0.223495</td>\n",
       "      <td>0.516668</td>\n",
       "      <td>1.247519</td>\n",
       "      <td>0.185523</td>\n",
       "      <td>{'math.MG_0908': 1.0, 'math.GN_1102': 0.0, 'ma...</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chunk_embedding_768_graph</td>\n",
       "      <td>0.249112</td>\n",
       "      <td>0.577946</td>\n",
       "      <td>1.317785</td>\n",
       "      <td>0.214867</td>\n",
       "      <td>{'math.MG_0908': 0.6666666666666666, 'math.GN_...</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.419355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  recall@10_raw  recall@10_adj  chunk_recall  \\\n",
       "0    chunk_embedding_768_dyn       0.223495       0.516668      1.247519   \n",
       "1  chunk_embedding_768_graph       0.249112       0.577946      1.317785   \n",
       "\n",
       "     MRR@10                                      slice_recalls  perturb_acc  \\\n",
       "0  0.185523  {'math.MG_0908': 1.0, 'math.GN_1102': 0.0, 'ma...        0.155   \n",
       "1  0.214867  {'math.MG_0908': 0.6666666666666666, 'math.GN_...        0.190   \n",
       "\n",
       "   failure_acc  \n",
       "0     0.258065  \n",
       "1     0.419355  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 4 — Evaluation loop   (40 % noise in ground‑truth handled)\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "import ast, os, time, math\n",
    "from collections import defaultdict\n",
    "import onnxruntime as ort\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ---------- helpers --------------------------------------------------------\n",
    "def recall_at_k(gt: list[str], retrieved: list[str], k:int = TOP_K) -> float:\n",
    "    if not gt:\n",
    "        return 0.0\n",
    "    hit = sum(1 for p in retrieved[:k] if p in gt)\n",
    "    return hit / len(gt)\n",
    "\n",
    "def adj_recall_at_k(gt: list[str], retrieved: list[str], k:int = TOP_K) -> float:\n",
    "    if not gt:\n",
    "        return 0.0\n",
    "    effective_rel = max(1, math.ceil(0.4 * len(gt)))          # assume 40 % relev.\n",
    "    hit = sum(1 for p in retrieved[:k] if p in gt)\n",
    "    return hit / effective_rel\n",
    "\n",
    "# ---------- main loop ------------------------------------------------------\n",
    "results        = []\n",
    "EMBED_TOKENIZER = \"distilbert/distilbert-base-uncased\"\n",
    "\n",
    "for mdl in MODEL_DETAILS:\n",
    "    col       = mdl[\"column\"]\n",
    "    onnx_path = mdl[\"model_path\"]\n",
    "    meta_file = f\"indexes/{col}_meta.jsonl\"\n",
    "    idx_file  = f\"indexes/{col}.index\"\n",
    "\n",
    "    logger.info(f\"=== Evaluating `{col}` with ONNX [{onnx_path}] ===\")\n",
    "\n",
    "    # ── 1.  Load / build FAISS index ───────────────────────────────────────\n",
    "    if os.path.exists(idx_file):\n",
    "        t0 = time.perf_counter()\n",
    "        index = faiss.read_index(idx_file)\n",
    "        logger.info(\"Loaded index `%s` in %.2fs\", idx_file, time.perf_counter()-t0)\n",
    "\n",
    "        if os.path.exists(meta_file):\n",
    "            df_emb = pd.read_json(meta_file, lines=True)\n",
    "        else:\n",
    "            df_emb = pd.read_sql(\n",
    "                f\"SELECT chunk_id, paper_cited FROM {TABLE_NAME}\",\n",
    "                con=engine\n",
    "            )\n",
    "            df_emb[\"paper_list\"] = (\n",
    "                df_emb[\"paper_cited\"].str.strip(\"{}\").str.split(\",\")\n",
    "            )\n",
    "            logger.info(\"Meta file missing – reloaded chunk_ids+paper_lists from Postgres\")\n",
    "\n",
    "    else:\n",
    "        t0  = time.perf_counter()\n",
    "        sql = f\"SELECT chunk_id, paper_cited, chunk_data, {col} FROM {TABLE_NAME}\"\n",
    "        df_emb = pd.read_sql(sql, con=engine)\n",
    "        df_emb[\"paper_list\"] = (\n",
    "            df_emb[\"paper_cited\"].str.strip(\"{}\").str.split(\",\")\n",
    "        )\n",
    "\n",
    "        df_emb[\"emb_list\"] = df_emb[col].apply(\n",
    "            lambda v: v if isinstance(v, list) else ast.literal_eval(v)\n",
    "        )\n",
    "        embs = np.array(df_emb[\"emb_list\"].tolist(), dtype=\"float32\")\n",
    "        faiss.normalize_L2(embs)\n",
    "\n",
    "        index = faiss.IndexFlatIP(embs.shape[1])\n",
    "        index.add(embs)\n",
    "\n",
    "        os.makedirs(\"indexes\", exist_ok=True)\n",
    "        faiss.write_index(index, idx_file)\n",
    "        df_emb[[\"chunk_id\", \"paper_list\"]].to_json(\n",
    "            meta_file, orient=\"records\", lines=True\n",
    "        )\n",
    "        logger.info(\"Built & saved index `%s` in %.2fs\", col, time.perf_counter()-t0)\n",
    "\n",
    "    chunk_ids   = df_emb[\"chunk_id\"].tolist()\n",
    "    paper_lists = df_emb[\"paper_list\"].tolist()\n",
    "\n",
    "    # ── 2.  ONNX session + tokenizer  +  sanity‑check───────────────────────\n",
    "    t1       = time.perf_counter()\n",
    "    ort_sess = ort.InferenceSession(\n",
    "        onnx_path, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(EMBED_TOKENIZER)\n",
    "    logger.info(\"Loaded ONNX session + tokenizer in %.2fs\", time.perf_counter()-t1)\n",
    "\n",
    "    # --- 2a.  encode_query helper -----------------------------------------\n",
    "    def encode_query(text: str):\n",
    "        toks = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"np\",\n",
    "            max_length=300,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        out = ort_sess.run(\n",
    "            None,\n",
    "            {\n",
    "                ort_sess.get_inputs()[0].name: toks[\"input_ids\"].astype(\"int64\"),\n",
    "                ort_sess.get_inputs()[1].name: toks[\"attention_mask\"].astype(\"int64\"),\n",
    "            },\n",
    "        )[0]\n",
    "        mask = np.expand_dims(toks[\"attention_mask\"], -1).astype(\"float32\")\n",
    "        emb  = (out * mask).sum(1) / np.clip(mask.sum(1), 1e-9, None)\n",
    "        faiss.normalize_L2(emb)\n",
    "        return emb.astype(\"float32\")\n",
    "\n",
    "    # --- 2b.  *sanity‑check* embedding path -------------------------------\n",
    "    sample = pd.read_sql(\n",
    "        f\"SELECT chunk_data, {col} FROM {TABLE_NAME} LIMIT 1\",\n",
    "        con=engine,\n",
    "    ).iloc[0]\n",
    "\n",
    "    offline_vec = np.array(\n",
    "        sample[col] if isinstance(sample[col], list) else ast.literal_eval(sample[col]),\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "    offline_vec = offline_vec / np.linalg.norm(offline_vec)  # ensure unit\n",
    "    online_vec  = encode_query(sample[\"chunk_data\"])[0]\n",
    "\n",
    "    cosine_sim  = float(np.dot(offline_vec, online_vec))\n",
    "    if cosine_sim < 0.90:\n",
    "        logger.warning(\n",
    "            \"Embedding mismatch for `%s` (cos = %.3f) – skipping this model.\",\n",
    "            col,\n",
    "            cosine_sim,\n",
    "        )\n",
    "        continue\n",
    "    logger.info(\"Embedding sanity‑check passed (cos = %.3f)\", cosine_sim)\n",
    "\n",
    "    # --- retrieval helper --------------------------------------------------\n",
    "    def retrieve_papers(q_emb, top_n=TOP_K):\n",
    "        D, I = index.search(q_emb, top_n * 20)        # bigger over‑fetch\n",
    "        paper2score = {}\n",
    "        for scores, idxs in zip(D, I):\n",
    "            for sc, idx in zip(scores, idxs):\n",
    "                for pid in paper_lists[idx]:\n",
    "                    paper2score[pid] = max(paper2score.get(pid, -1e9), sc)\n",
    "        return [p for p, _ in sorted(paper2score.items(), key=lambda x: -x[1])][:top_n], I\n",
    "\n",
    "    # ── 3.  Held‑out evaluation (paper + chunk recall) ─────────────────────\n",
    "    raw_rec   = []\n",
    "    adj_rec   = []\n",
    "    chunk_rec = []          # NEW\n",
    "    mrrs      = []\n",
    "\n",
    "    for rec in heldout:\n",
    "        q_emb          = encode_query(rec[\"query\"])\n",
    "        top_papers, I  = retrieve_papers(q_emb)\n",
    "        raw_rec.append(recall_at_k(rec[\"ground_truth\"], top_papers))\n",
    "        adj_rec.append(adj_recall_at_k(rec[\"ground_truth\"], top_papers))\n",
    "        mrrs.append(mrr_at_k(rec[\"ground_truth\"], top_papers))\n",
    "\n",
    "        # chunk‑level recall ⟶ any retrieved *chunk* from a GT paper?\n",
    "        top_chunk_hit = sum(\n",
    "            1\n",
    "            for idx in I[0][: TOP_K * 20]\n",
    "            if any(pid in rec[\"ground_truth\"] for pid in paper_lists[idx])\n",
    "        )\n",
    "        chunk_rec.append(top_chunk_hit / max(1, len(rec[\"ground_truth\"])))\n",
    "\n",
    "    logger.info(\n",
    "        \"→ Held‑out Recall@%d (raw|adj|chunk) = %.4f | %.4f | %.4f ,  MRR@%d = %.4f\",\n",
    "        TOP_K,\n",
    "        np.mean(raw_rec),\n",
    "        np.mean(adj_rec),\n",
    "        np.mean(chunk_rec),\n",
    "        TOP_K,\n",
    "        np.mean(mrrs),\n",
    "    )\n",
    "\n",
    "    # ── 4.  Slice evaluation (adjusted recall) ─────────────────────────────\n",
    "    slice_scores = defaultdict(list)\n",
    "    for rec in slices:\n",
    "        tops, _ = retrieve_papers(encode_query(rec[\"query\"]))\n",
    "        slice_scores[rec[\"slice\"]].append(\n",
    "            adj_recall_at_k(rec[\"ground_truth\"], tops)\n",
    "        )\n",
    "    logger.info(\"→ Slice count: %d\", len(slice_scores))\n",
    "\n",
    "    # ── 5.  Perturbation / failure‑mode checks (unchanged) ─────────────────\n",
    "    perturb_ok = [\n",
    "        retrieve_papers(encode_query(r[\"perturbed\"]), 1)[0][0] in r[\"expected_papers\"]\n",
    "        for r in perturbs\n",
    "    ]\n",
    "    logger.info(\"→ Perturbation pass rate %.4f\", np.mean(perturb_ok))\n",
    "\n",
    "    failure_ok = [\n",
    "        retrieve_papers(encode_query(r[\"query\"]), 1)[0][0] in r[\"correct_papers\"]\n",
    "        for r in failures\n",
    "    ]\n",
    "    logger.info(\"→ Failure‑mode pass rate %.4f\", np.mean(failure_ok))\n",
    "\n",
    "    # ── 6.  Collect results  ───────────────────────────────────────────────\n",
    "    results.append(\n",
    "        {\n",
    "            \"model\":           col,\n",
    "            \"recall@10_raw\":   np.mean(raw_rec),\n",
    "            \"recall@10_adj\":   np.mean(adj_rec),\n",
    "            \"chunk_recall\":    np.mean(chunk_rec),\n",
    "            \"MRR@10\":          np.mean(mrrs),\n",
    "            \"slice_recalls\":   {s: np.mean(v) for s, v in slice_scores.items()},\n",
    "            \"perturb_acc\":     np.mean(perturb_ok),\n",
    "            \"failure_acc\":     np.mean(failure_ok),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# ---------- save & show ----------------------------------------------------\n",
    "df_res = pd.DataFrame(results)\n",
    "os.makedirs(\"eval\", exist_ok=True)\n",
    "df_res.to_json(\"eval/model_comparison.jsonl\", orient=\"records\", lines=True)\n",
    "logger.info(\"Done! Results written to eval/model_comparison.jsonl\")\n",
    "df_res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
