{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Found existing installation: psycopg2-binary 2.9.10\n",
      "Uninstalling psycopg2-binary-2.9.10:\n",
      "  Successfully uninstalled psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.10-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y psycopg2-binary\n",
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "import unicodedata\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.dialects.postgresql import ARRAY, TEXT\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sqlalchemy import inspect\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import psycopg2\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerModel(\n",
       "  (embeddings): LongformerEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): LongformerEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x LongformerLayer(\n",
       "        (attention): LongformerAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): LongformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): LongformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): LongformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): LongformerPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_DIR = \"/Users/riyagarg/Downloads/prepare_eval_data/longformer_model2/model.sentence_transformer\"\n",
    "\n",
    "# ── ❷ Load tokenizer & model from local files ────────────────────\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_DIR, local_files_only=True)\n",
    "model     = AutoModel.from_pretrained(   HF_DIR, local_files_only=True)\n",
    "model.eval()  # disable dropout, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (2, 768)\n",
      "First vector (first 5 dims): [-0.02423628 -0.0608274   0.4972675   0.30362946  0.11610436]\n",
      "Second vector norm: 16.511986\n"
     ]
    }
   ],
   "source": [
    "#Testing the model\n",
    "\n",
    "# ── ❸ Prepare some texts ─────────────────────────────────────────\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Longformer can process documents up to 4096 tokens!\"\n",
    "]\n",
    "\n",
    "# ── ❹ Tokenize (returns PyTorch tensors) ───────────────────────────\n",
    "inputs = tokenizer(\n",
    "    texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=4096\n",
    ")\n",
    "\n",
    "# ── ❺ Forward pass to get last hidden states ───────────────────────\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden = outputs.last_hidden_state          \n",
    "\n",
    "# ── ❻ Mean‐pool over the token dimension, masking PADs ─────────────\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "masked_hidden  = last_hidden * attention_mask          \n",
    "sum_hidden     = masked_hidden.sum(dim=1)              \n",
    "counts         = attention_mask.sum(dim=1).clamp(min=1e-9)      \n",
    "embeddings     = (sum_hidden / counts).cpu().numpy()            \n",
    "\n",
    "# ── ❼ Inspect ───────────────────────────────────────────────────────\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"First vector (first 5 dims):\", embeddings[0][:5])\n",
    "print(\"Second vector norm:\", np.linalg.norm(embeddings[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS  = 4\n",
    "MODEL_DIR = \"/Users/riyagarg/Downloads/prepare_eval_data/longformer_model2/model.sentence_transformer\"\n",
    "DATABASE_URI = 'postgresql+psycopg2://rg5073:rg5073pass@129.114.27.112:5432/cleaned_meta_data_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URI, pool_size=8, max_overflow=0)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "      ALTER TABLE arxiv_chunks_eval_4\n",
    "      ADD COLUMN IF NOT EXISTS chunk_embedding_768 vector(768)\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerModel(\n",
       "  (embeddings): LongformerEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): LongformerEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x LongformerLayer(\n",
       "        (attention): LongformerAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): LongformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): LongformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): LongformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): LongformerPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    total = conn.execute(text(\"SELECT COUNT(*) FROM arxiv_chunks_eval_4\")).scalar_one()\n",
    "\n",
    "# ───────────── LOAD MODEL & TOKENIZER ─────────────────\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)\n",
    "model     = AutoModel.from_pretrained(MODEL_DIR, local_files_only=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts):\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=4096\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        last_hidden = model(**inputs).last_hidden_state  # (N, T, D)\n",
    "    mask   = inputs['attention_mask'].unsqueeze(-1)    # (N, T, 1)\n",
    "    summed = (last_hidden * mask).sum(dim=1)           # (N, D)\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-9)           # (N, 1)\n",
    "    return (summed / counts).cpu().numpy()             # (N, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(offset: int):\n",
    "    \"\"\"\n",
    "    Fetches one batch (by OFFSET), embeds, then bulk-updates.\n",
    "    Returns number of rows written.\n",
    "    \"\"\"\n",
    "    # 1) fetch batch\n",
    "    with engine.connect() as conn:\n",
    "        rows = conn.execute(\n",
    "            text(\"\"\"\n",
    "              SELECT paper_id, chunk_id, chunk_data\n",
    "                FROM arxiv_chunks_eval_4\n",
    "               ORDER BY paper_id, chunk_id\n",
    "               LIMIT :limit OFFSET :offset\n",
    "            \"\"\"),\n",
    "            {\"limit\": BATCH_SIZE, \"offset\": offset}\n",
    "        ).fetchall()\n",
    "\n",
    "    if not rows:\n",
    "        return 0\n",
    "\n",
    "    # 2) compute embeddings\n",
    "    ids   = [(r.paper_id, r.chunk_id) for r in rows]\n",
    "    texts = [r.chunk_data for r in rows]\n",
    "    embs  = embed_texts(texts)  # shape (len(rows), 768)\n",
    "\n",
    "    # 3) bulk update\n",
    "    params = [\n",
    "        {\"pid\": pid, \"cid\": cid, \"vec\": vec.tolist()}\n",
    "        for (pid, cid), vec in zip(ids, embs)\n",
    "    ]\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(\n",
    "            text(\"\"\"\n",
    "              UPDATE arxiv_chunks_eval_4\n",
    "                 SET chunk_embedding_768 = :vec\n",
    "               WHERE paper_id = :pid\n",
    "                 AND chunk_id   = :cid\n",
    "            \"\"\"),\n",
    "            params\n",
    "        )\n",
    "\n",
    "    return len(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = math.ceil(total / BATCH_SIZE)\n",
    "offsets   = [i * BATCH_SIZE for i in range(n_batches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "… done 2256/52554 rows\r"
     ]
    }
   ],
   "source": [
    "processed = 0\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    futures = {executor.submit(process_batch, off): off for off in offsets}\n",
    "    for fut in as_completed(futures):\n",
    "        done = fut.result()\n",
    "        processed += done\n",
    "        print(f\"… done {processed}/{total} rows\", end=\"\\r\")\n",
    "\n",
    "print(f\"\\n✅ Finished embedding & updating {processed} rows into chunk_embedding_768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
