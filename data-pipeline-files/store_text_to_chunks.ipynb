{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67deab-dd1a-4bc8-9861-a9a5b12456c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container \n",
    "import os\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "import unicodedata\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.dialects.postgresql import ARRAY, TEXT\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb771ece-32c2-4222-a22c-9b656f254fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_files_list.txt', 'metadata', 'raw-data', 'text-files-data']\n"
     ]
    }
   ],
   "source": [
    "meta_data_dir = os.getenv(\"META_DATA_DIR\", \"/mnt/metadata\")\n",
    "print(os.listdir(meta_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f081d9bf-fc0b-48c5-9cb4-31681dc5842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text_arxiv_0801.tar', 'text_arxiv_0802.tar', 'text_arxiv_0803.tar', 'text_arxiv_0804.tar', 'text_arxiv_0805.tar', 'text_arxiv_0806.tar', 'text_arxiv_0807.tar', 'text_arxiv_0808.tar', 'text_arxiv_0809.tar', 'text_arxiv_0810.tar', 'text_arxiv_0811.tar', 'text_arxiv_0812.tar', 'text_arxiv_0901.tar', 'text_arxiv_0902.tar', 'text_arxiv_0903.tar', 'text_arxiv_0904.tar', 'text_arxiv_0905.tar', 'text_arxiv_0906.tar', 'text_arxiv_0907.tar', 'text_arxiv_0908.tar', 'text_arxiv_0909.tar', 'text_arxiv_0910.tar', 'text_arxiv_0911.tar', 'text_arxiv_0912.tar', 'text_arxiv_1001.tar', 'text_arxiv_1002.tar', 'text_arxiv_1004.tar', 'text_arxiv_1005.tar', 'text_arxiv_1006.tar', 'text_arxiv_1007.tar', 'text_arxiv_1008.tar', 'text_arxiv_1009.tar', 'text_arxiv_1010.tar', 'text_arxiv_1011.tar', 'text_arxiv_1012.tar', 'text_arxiv_1101.tar', 'text_arxiv_1102.tar', 'text_arxiv_1103.tar', 'text_arxiv_1104.tar', 'text_arxiv_1105.tar', 'text_arxiv_1106.tar', 'text_arxiv_1107.tar']\n"
     ]
    }
   ],
   "source": [
    "text_files_data_path = os.path.join(meta_data_dir, \"text-files-data\")\n",
    "\n",
    "# List the contents of that subfolder\n",
    "tar_files_list = os.listdir(text_files_data_path)\n",
    "print(tar_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "287b5886-634f-43fc-a460-527ecb6513ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    'postgresql+psycopg2://rg5073:rg5073pass@cleaned_meta_data_postgres:5432/cleaned_meta_data_db',\n",
    "    pool_size=10,\n",
    "    max_overflow=0,\n",
    "    pool_timeout=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd7e78ae-4bd3-43a9-b4fc-37ab9abf274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = 0\n",
    "fail_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9a3e3d1-a8ff-4eca-984a-f3d23940bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text files to process: 227494\n"
     ]
    }
   ],
   "source": [
    "# ‚ö°Ô∏è Load existing filenames (once\n",
    "def load_existing_pdf_filenames():\n",
    "    query = text(\"SELECT txt_filename FROM arxiv_metadata;\")\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        pdf_filenames = {row[0] for row in result.fetchall()}\n",
    "    return pdf_filenames\n",
    "existing_pdf_filenames = load_existing_pdf_filenames()\n",
    "print(\"Total text files to process:\", len(existing_pdf_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9547ae95-66cb-49fd-815b-28757521710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê Chunking function\n",
    "def chunk_text(text, chunk_size_words=650):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size_words):\n",
    "        chunks.append(\" \".join(words[i:i+chunk_size_words]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc875472-140a-452c-8d08-4fde0c2e3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clean_text_remove_references(text):\n",
    "    # 1. Remove null bytes\n",
    "    text = text.replace('\\x00', '')\n",
    "\n",
    "    # 2. Normalize Unicode (like Ô¨Å ‚Üí fi)\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "\n",
    "    # 3. Remove inline LaTeX/math ($...$) and LaTeX commands (\\command{...})\n",
    "    text = re.sub(r'\\$.*?\\$', ' ', text)                 # Remove math in $\n",
    "    text = re.sub(r'\\\\[a-zA-Z]+\\{.*?\\}', ' ', text)       # Remove \\commands{...}\n",
    "    \n",
    "    # 4. Remove Unicode math symbols and special symbols (sets, operators, etc)\n",
    "    text = re.sub(r'[\\u2200-\\u22FF\\u2300-\\u23FF]', ' ', text)\n",
    "\n",
    "    # 5. Remove anything between ‚ü®...‚ü© (angle brackets)\n",
    "    text = re.sub(r'‚ü®.*?‚ü©', ' ', text)\n",
    "\n",
    "    # 6. Remove references like [1], [2,5,10]\n",
    "    text = re.sub(r'\\[\\d+(,\\s*\\d+)*\\]', ' ', text)\n",
    "\n",
    "    # 7. Remove numbered equations like (123), (4.5)\n",
    "    text = re.sub(r'\\(\\d+(\\.\\d+)?\\)', ' ', text)\n",
    "\n",
    "    # 8. Remove any remaining weird LaTeX leftovers like {some text}\n",
    "    text = re.sub(r'\\{.*?\\}', ' ', text)\n",
    "\n",
    "    # 9. Remove equations written like \"E = mc^2\" (detect common formula style)\n",
    "    text = re.sub(r'([A-Za-z0-9]+\\s*[=<>]\\s*[A-Za-z0-9^+\\-*/\\s]+)', ' ', text)\n",
    "\n",
    "    # 10. Remove all non-ASCII except basic punctuations\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    # 11. Remove any special characters except basic word characters and sentence punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\,\\?\\!]', ' ', text)\n",
    "\n",
    "    # 12. Remove extra hyphenated line breaks\n",
    "    text = re.sub(r'-\\n\\s*', '', text)\n",
    "\n",
    "    # 13. Collapse multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # 14. üö® Remove the References section completely\n",
    "    text = re.split(r'\\bReferences\\b', text, flags=re.IGNORECASE)[0]\n",
    "\n",
    "    # 15. Final strip\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b34bb6f3-8751-45d1-abda-73106f75e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê Per-file processing (for parallel chunking)\n",
    "def process_single_file(task):\n",
    "    file_path, txt_filename = task\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text_content = f.read()\n",
    "        cleaned_text = simple_clean_text_remove_references(text_content)\n",
    "        chunks = chunk_text(cleaned_text)\n",
    "        paper_id = txt_filename.replace(\".txt\", \"\")\n",
    "        return (paper_id, txt_filename, chunks)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Chunking failed for {txt_filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72c75ec4-e3dc-4ea8-a088-960d9b1a3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê Parallel INSERT into arxiv_chunks\n",
    "def insert_chunks(conn, entries):\n",
    "    \"\"\"\n",
    "    entries: list of (paper_id, txt_filename, chunks_list)\n",
    "    \"\"\"\n",
    "    inserts = []\n",
    "    for paper_id, txt_filename, chunks in entries:\n",
    "        for idx, chunk in enumerate(chunks, start=1):\n",
    "            inserts.append({\n",
    "                \"paper_id\": paper_id,\n",
    "                \"chunk_id\": idx,\n",
    "                \"txt_filename\": txt_filename,\n",
    "                \"query\": \"\",  # optional: you can populate later\n",
    "                \"chunk_data\": chunk\n",
    "            })\n",
    "\n",
    "    if not inserts:\n",
    "        return\n",
    "\n",
    "    insert_stmt = text(\"\"\"\n",
    "        INSERT INTO arxiv_chunks (paper_id, chunk_id, txt_filename, query, chunk_data)\n",
    "        VALUES (:paper_id, :chunk_id, :txt_filename, :query, :chunk_data)\n",
    "    \"\"\")\n",
    "\n",
    "    batch_size = 500  # Adjust based on memory\n",
    "    for i in tqdm(range(0, len(inserts), batch_size), desc=\"Inserting into arxiv_chunks\"):\n",
    "        batch = inserts[i:i+batch_size]\n",
    "        conn.execute(insert_stmt, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d23b1d8-7384-499e-801a-cb960e8ea867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê Per-tar processing\n",
    "def process_tar_file(tar_filename):\n",
    "    global total_files, fail_count\n",
    "\n",
    "    tar_path = os.path.join(text_files_data_path, tar_filename)\n",
    "\n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"‚ùå Tar file not found: {tar_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüì¶ Processing tar: {tar_filename}...\")\n",
    "\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=workspace_dir)\n",
    "\n",
    "    extracted_folder_name = tar_filename.replace(\".tar\", \"\")\n",
    "    extracted_folder_path = os.path.join(workspace_dir, extracted_folder_name)\n",
    "\n",
    "    if not os.path.exists(extracted_folder_path):\n",
    "        print(f\"‚ùå Extracted folder missing: {extracted_folder_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîç Extracted to: {extracted_folder_path}\")\n",
    "\n",
    "    txt_files_list = os.listdir(extracted_folder_path)\n",
    "    print(f\"üìÑ Found {len(txt_files_list)} text files.\")\n",
    "\n",
    "    tasks = []\n",
    "    for filename in txt_files_list:\n",
    "        if filename.endswith(\".txt\") and filename in existing_pdf_filenames:\n",
    "            file_path = os.path.join(extracted_folder_path, filename)\n",
    "            tasks.append((file_path, filename))\n",
    "\n",
    "    if not tasks:\n",
    "        print(f\"‚ö†Ô∏è No matching text files found in {tar_filename}\")\n",
    "        shutil.rmtree(extracted_folder_path)\n",
    "        return\n",
    "\n",
    "    # ‚≠ê Process all files in parallel\n",
    "    with Pool(processes=8) as pool:\n",
    "        results = list(tqdm(\n",
    "            pool.imap_unordered(process_single_file, tasks),\n",
    "            total=len(tasks),\n",
    "            desc=f\"Chunking {tar_filename}\",\n",
    "            dynamic_ncols=True\n",
    "        ))\n",
    "\n",
    "    processed_entries = [r for r in results if r is not None]\n",
    "\n",
    "    print(f\"‚úÖ Processed {len(processed_entries)} / {len(tasks)} files ready for DB insert.\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        try:\n",
    "            insert_chunks(conn, processed_entries)\n",
    "            total_files += len(processed_entries)\n",
    "        except Exception as e:\n",
    "            fail_count += len(processed_entries)\n",
    "            print(f\"‚ùå Insert failed for {tar_filename}: {e}\")\n",
    "\n",
    "    shutil.rmtree(extracted_folder_path)\n",
    "    print(f\"üßπ Deleted extracted folder: {extracted_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31f37e7b-10b7-45cd-a4d0-ec299dc15003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Processing tar: text_arxiv_0801.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064/3612149096.py:14: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=workspace_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0801\n",
      "üìÑ Found 7683 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0801.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4935/4935 [00:08<00:00, 584.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4935 / 4935 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:11<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0801\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0802.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0802\n",
      "üìÑ Found 6934 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0802.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4431/4431 [00:07<00:00, 579.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4431 / 4431 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [00:10<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0802\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0803.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0803\n",
      "üìÑ Found 7123 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0803.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4489/4489 [00:08<00:00, 558.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4489 / 4489 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:10<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0803\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0804.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0804\n",
      "üìÑ Found 7748 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0804.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4862/4862 [00:08<00:00, 571.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4862 / 4862 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [00:11<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0804\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0805.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0805\n",
      "üìÑ Found 7564 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0805.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4805/4805 [00:08<00:00, 573.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4805 / 4805 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83/83 [00:10<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0805\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0806.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0806\n",
      "üìÑ Found 7996 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0806.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4936/4936 [00:08<00:00, 576.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4936 / 4936 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85/85 [00:11<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0806\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0807.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0807\n",
      "üìÑ Found 8193 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0807.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5090/5090 [00:09<00:00, 536.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5090 / 5090 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [00:12<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0807\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0808.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0808\n",
      "üìÑ Found 6551 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0808.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4143/4143 [00:07<00:00, 558.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4143 / 4143 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:09<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0808\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0809.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0809\n",
      "üìÑ Found 8427 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0809.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5254/5254 [00:09<00:00, 564.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5254 / 5254 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 93/93 [00:13<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0809\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0810.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0810\n",
      "üìÑ Found 8807 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0810.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5736/5736 [00:09<00:00, 584.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5736 / 5736 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97/97 [00:12<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0810\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0811.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0811\n",
      "üìÑ Found 7451 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0811.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4739/4739 [00:08<00:00, 576.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4739 / 4739 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:10<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0811\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0812.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0812\n",
      "üìÑ Found 8161 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0812.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5087/5087 [00:08<00:00, 568.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5087 / 5087 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91/91 [00:12<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0812\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0901.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0901\n",
      "üìÑ Found 8000 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0901.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4931/4931 [00:08<00:00, 571.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4931 / 4931 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85/85 [00:11<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0901\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0902.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0902\n",
      "üìÑ Found 7665 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0902.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4865/4865 [00:08<00:00, 569.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4865 / 4865 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:11<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0902\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0903.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0903\n",
      "üìÑ Found 8974 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0903.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5506/5506 [00:09<00:00, 550.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5506 / 5506 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [00:13<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0903\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0904.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0904\n",
      "üìÑ Found 7897 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0904.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4899/4899 [00:08<00:00, 547.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4899 / 4899 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:12<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0904\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0905.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0905\n",
      "üìÑ Found 7874 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0905.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4912/4912 [00:08<00:00, 558.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4912 / 4912 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87/87 [00:11<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0905\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0906.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0906\n",
      "üìÑ Found 8864 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0906.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5578/5578 [00:10<00:00, 541.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5578 / 5578 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:13<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0906\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0907.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0907\n",
      "üìÑ Found 9076 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0907.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5563/5563 [00:10<00:00, 553.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5563 / 5563 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [00:13<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0907\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0908.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0908\n",
      "üìÑ Found 7279 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0908.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4559/4559 [00:08<00:00, 552.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4559 / 4559 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [00:10<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0908\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0909.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0909\n",
      "üìÑ Found 8725 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0909.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5656/5656 [00:10<00:00, 532.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5656 / 5656 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [00:12<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0909\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0910.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0910\n",
      "üìÑ Found 9162 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0910.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5907/5907 [00:10<00:00, 569.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5907 / 5907 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [00:13<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0910\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0911.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0911\n",
      "üìÑ Found 9115 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0911.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5685/5685 [00:10<00:00, 559.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5685 / 5685 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:13<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0911\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_0912.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_0912\n",
      "üìÑ Found 8792 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_0912.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5477/5477 [00:10<00:00, 543.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5477 / 5477 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97/97 [00:12<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_0912\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1001.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1001\n",
      "üìÑ Found 8541 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1001.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5423/5423 [00:09<00:00, 559.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5423 / 5423 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91/91 [00:12<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1001\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1002.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1002\n",
      "üìÑ Found 7982 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1002.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4987/4987 [00:09<00:00, 544.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 4987 / 4987 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [00:11<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1002\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1004.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1004\n",
      "üìÑ Found 8955 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1004.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5543/5543 [00:10<00:00, 511.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5543 / 5543 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:13<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1004\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1005.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1005\n",
      "üìÑ Found 9192 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1005.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5683/5683 [00:10<00:00, 549.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5683 / 5683 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [00:12<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1005\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1006.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1006\n",
      "üìÑ Found 9428 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1006.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5877/5877 [00:10<00:00, 549.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5877 / 5877 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:13<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1006\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1007.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1007\n",
      "üìÑ Found 8817 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1007.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5462/5462 [00:09<00:00, 552.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5462 / 5462 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [00:13<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1007\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1008.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1008\n",
      "üìÑ Found 8633 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1008.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5337/5337 [00:09<00:00, 543.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5337 / 5337 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:12<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1008\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1009.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1009\n",
      "üìÑ Found 9724 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1009.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6172/6172 [00:11<00:00, 540.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 6172 / 6172 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111/111 [00:14<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1009\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1010.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1010\n",
      "üìÑ Found 9806 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1010.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6212/6212 [00:11<00:00, 544.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 6212 / 6212 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110/110 [00:14<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1010\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1011.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1011\n",
      "üìÑ Found 10562 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1011.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6606/6606 [00:12<00:00, 539.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 6606 / 6606 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [00:14<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1011\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1012.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1012\n",
      "üìÑ Found 9581 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1012.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5976/5976 [00:10<00:00, 551.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5976 / 5976 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:14<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1012\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1101.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1101\n",
      "üìÑ Found 9775 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1101.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6012/6012 [00:11<00:00, 543.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 6012 / 6012 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 106/106 [00:14<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1101\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1102.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1102\n",
      "üìÑ Found 9227 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1102.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5715/5715 [00:10<00:00, 549.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5715 / 5715 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:13<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1102\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1103.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1103\n",
      "üìÑ Found 10151 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1103.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6215/6215 [00:11<00:00, 538.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 6215 / 6215 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [00:15<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1103\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1104.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1104\n",
      "üìÑ Found 9289 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1104.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5652/5652 [00:10<00:00, 521.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5652 / 5652 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104/104 [00:14<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1104\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1105.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1105\n",
      "üìÑ Found 10321 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1105.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6311/6311 [00:11<00:00, 548.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 6311 / 6311 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:15<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1105\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1106.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1106\n",
      "üìÑ Found 10267 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1106.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6280/6280 [00:12<00:00, 517.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 6280 / 6280 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 117/117 [00:16<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1106\n",
      "\n",
      "üì¶ Processing tar: text_arxiv_1107.tar...\n",
      "üîç Extracted to: /home/jovyan/work/text_arxiv_1107\n",
      "üìÑ Found 9756 text files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking text_arxiv_1107.tar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5986/5986 [00:11<00:00, 516.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 5986 / 5986 files ready for DB insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting into arxiv_chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111/111 [00:15<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deleted extracted folder: /home/jovyan/work/text_arxiv_1107\n",
      "\n",
      "üéâ All tar files processed!\n",
      "üî• Total papers inserted: 227494\n",
      "‚ùó Total failed inserts: 0\n"
     ]
    }
   ],
   "source": [
    "for tar_filename in tar_files_list:\n",
    "    process_tar_file(tar_filename)\n",
    "\n",
    "print(\"\\nüéâ All tar files processed!\")\n",
    "print(f\"üî• Total papers inserted: {total_files}\")\n",
    "print(f\"‚ùó Total failed inserts: {fail_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44824e68-880d-459b-a2c4-3774e15e0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total rows in arxiv_chunks: 2008087\n"
     ]
    }
   ],
   "source": [
    "query_count = \"SELECT COUNT(*) FROM arxiv_chunks;\"\n",
    "count = pd.read_sql(query_count, engine)\n",
    "print(\"‚úÖ Total rows in arxiv_chunks:\", count.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96796280-a7b7-42a8-a72b-93fa54e909d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preview of data:\n",
      "      paper_id  chunk_id     txt_filename query  \\\n",
      "0  0801.3173v1         1  0801.3173v1.txt         \n",
      "1  0801.3173v1         2  0801.3173v1.txt         \n",
      "2  0801.1596v1         1  0801.1596v1.txt         \n",
      "3  0801.1596v1         2  0801.1596v1.txt         \n",
      "4  0801.1596v1         3  0801.1596v1.txt         \n",
      "\n",
      "                                                                                                                                                                                                chunk_data  \n",
      "0  arXiv 0801.3173v1 astro ph 21 Jan 2008 The impact of encounters on the members of Local Group Analogs. A view from GALEX Buson, L. M.1, Bettoni, D.1, Bianchi, L.2, Buzzoni, A.3, Marino, A.1 and Ra...  \n",
      "1  c? 14.18 1101 18.01 0.01 18.51 0.03 0.50 0.03 NGC 3455 R SAB rs b 12.83 1102 14.719 0.01 NGC 3507 SB s b 11.73 979 16.90 0.03 18.21 0.08 1.31 0.09 UGC 5947 Im pec. 14.75 1251 UGC 6035 IBm 14.30 10...  \n",
      "2  arXiv 0801.1596v1 cond mat.mes hall 10 Jan 2008 Transport Length Scales in Disordered Graphene based Materials Strong Localization Regimes and Dimensionality Effects Aur elien Lherbier1,3, Blanca ...  \n",
      "3  explored but fiercely debated . In this Letter, by using both the Kubo and Landauer approaches, the transport length scales in 2D graphene are investigated and compared with those of the quasi 1D ...  \n",
      "4  disorder strength W or increasing charge energy E . At longer times, D E, t decreases owing to quantum interferences effects and localization phenomena . The full energy dependence of le is given ...  \n"
     ]
    }
   ],
   "source": [
    "query_preview = \"SELECT * FROM arxiv_chunks LIMIT 5;\"\n",
    "preview = pd.read_sql(query_preview, engine)\n",
    "print(\"‚úÖ Preview of data:\")\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3c6574d-7397-4ac2-8282-f553c77d1d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Rows with NULL id or txt_filename: 0\n"
     ]
    }
   ],
   "source": [
    "query_nulls = \"\"\"\n",
    "SELECT COUNT(*) \n",
    "FROM arxiv_metadata \n",
    "WHERE id IS NULL OR txt_filename IS NULL;\n",
    "\"\"\"\n",
    "nulls = pd.read_sql(query_nulls, engine)\n",
    "print(\"‚úÖ Rows with NULL id or txt_filename:\", nulls.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe5935af-4c5b-450f-8139-be680e229a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>txt_filename</th>\n",
       "      <th>query</th>\n",
       "      <th>chunk_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0801.0001v1</td>\n",
       "      <td>1</td>\n",
       "      <td>0801.0001v1.txt</td>\n",
       "      <td></td>\n",
       "      <td>arXiv:0801.0001v1 [math.NT] 2 Jan 2008 LINEAR FORMS AND COMPLEMENTING SETS OF INTEGERS MELVYN B. NATHANSON Abstract. Let œÜ(x1, . . . , xh, y) = u1x1 + ¬∑ ¬∑ ¬∑ + uhxh + vy be a linear form with nonze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0801.0001v1</td>\n",
       "      <td>2</td>\n",
       "      <td>0801.0001v1.txt</td>\n",
       "      <td></td>\n",
       "      <td>, ah, b1, . . . , bl) A1 √ó ¬∑ ¬∑ ¬∑ √ó Ah √ó B1 √ó ¬∑ ¬∑ ¬∑ √ó Bl: œÜ(a1, . . . , ah, b1, . . . , bl) n (mod m)}) . If l= 1 and B = (B), then we write œÜ(A, B) = œÜ(A, B), R(œÜ) A,B(n) = R(œÜ) A,B(n), and R(œÜ) A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0801.0001v1</td>\n",
       "      <td>3</td>\n",
       "      <td>0801.0001v1.txt</td>\n",
       "      <td></td>\n",
       "      <td>case l= 1. Suppose that œÜ(x1, . . . , xh, y) = œà(x1, . . . , xh)+vy is a linear form with nonzero integer coefficients, and that A is an h-tuple of finite sets of integers and B is a set of intege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0801.0001v1</td>\n",
       "      <td>4</td>\n",
       "      <td>0801.0001v1.txt</td>\n",
       "      <td></td>\n",
       "      <td>&lt; œà(a1, . . . , ah) gmax for all h-tuples (a1, . . . , ah) /Gmin, it follows that 0 &lt; 1 v œà(a1, . . . , ah) gmin uh gmax gmin uh . Similarly, replacing n by vn + gmax, we obtain the identity |Gmax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0801.0001v1</td>\n",
       "      <td>5</td>\n",
       "      <td>0801.0001v1.txt</td>\n",
       "      <td></td>\n",
       "      <td>l=0 X iIl R(œà) A (l+ im)zl+im. Since zLF(z) = m1 X l=0 X iIl R(œà) A (l+ im)zl+L+im is a polynomial, it follows that l+ L + im 0 for all l{0, 1, . . ., m 1} and i Il. Applying the division algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0801.0001v1</td>\n",
       "      <td>6</td>\n",
       "      <td>0801.0001v1.txt</td>\n",
       "      <td></td>\n",
       "      <td>LN N for all N 1, we can assume without loss of generality that LN = N. Consider the linear form œà(x1, . . . , xh) = u1x1 + ¬∑ ¬∑ ¬∑ + uhxh Then œÜ(a1, . . . , ah, b) = œà(a1, . . . , a) + vb for all i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0801.0001v1</td>\n",
       "      <td>7</td>\n",
       "      <td>0801.0001v1.txt</td>\n",
       "      <td></td>\n",
       "      <td>n IN. Then there exists a set B such that RA,B(n) = t for all n Z. Proof. For every integer N 1, there is an integer cN such that IN = [cN LN, cN + LN] Z. Replace the set BN with the set BN cN and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  chunk_id     txt_filename query  \\\n",
       "0  0801.0001v1         1  0801.0001v1.txt         \n",
       "1  0801.0001v1         2  0801.0001v1.txt         \n",
       "2  0801.0001v1         3  0801.0001v1.txt         \n",
       "3  0801.0001v1         4  0801.0001v1.txt         \n",
       "4  0801.0001v1         5  0801.0001v1.txt         \n",
       "5  0801.0001v1         6  0801.0001v1.txt         \n",
       "6  0801.0001v1         7  0801.0001v1.txt         \n",
       "\n",
       "                                                                                                                                                                                                chunk_data  \n",
       "0  arXiv:0801.0001v1 [math.NT] 2 Jan 2008 LINEAR FORMS AND COMPLEMENTING SETS OF INTEGERS MELVYN B. NATHANSON Abstract. Let œÜ(x1, . . . , xh, y) = u1x1 + ¬∑ ¬∑ ¬∑ + uhxh + vy be a linear form with nonze...  \n",
       "1  , ah, b1, . . . , bl) A1 √ó ¬∑ ¬∑ ¬∑ √ó Ah √ó B1 √ó ¬∑ ¬∑ ¬∑ √ó Bl: œÜ(a1, . . . , ah, b1, . . . , bl) n (mod m)}) . If l= 1 and B = (B), then we write œÜ(A, B) = œÜ(A, B), R(œÜ) A,B(n) = R(œÜ) A,B(n), and R(œÜ) A...  \n",
       "2  case l= 1. Suppose that œÜ(x1, . . . , xh, y) = œà(x1, . . . , xh)+vy is a linear form with nonzero integer coefficients, and that A is an h-tuple of finite sets of integers and B is a set of intege...  \n",
       "3  < œà(a1, . . . , ah) gmax for all h-tuples (a1, . . . , ah) /Gmin, it follows that 0 < 1 v œà(a1, . . . , ah) gmin uh gmax gmin uh . Similarly, replacing n by vn + gmax, we obtain the identity |Gmax...  \n",
       "4  l=0 X iIl R(œà) A (l+ im)zl+im. Since zLF(z) = m1 X l=0 X iIl R(œà) A (l+ im)zl+L+im is a polynomial, it follows that l+ L + im 0 for all l{0, 1, . . ., m 1} and i Il. Applying the division algorith...  \n",
       "5  LN N for all N 1, we can assume without loss of generality that LN = N. Consider the linear form œà(x1, . . . , xh) = u1x1 + ¬∑ ¬∑ ¬∑ + uhxh Then œÜ(a1, . . . , ah, b) = œà(a1, . . . , a) + vb for all i...  \n",
       "6  n IN. Then there exists a set B such that RA,B(n) = t for all n Z. Proof. For every integer N 1, there is an integer cN such that IN = [cN LN, cN + LN] Z. Replace the set BN with the set BN cN and...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_id = \"0801.0001v1\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT paper_id, chunk_id, txt_filename, query, chunk_data\n",
    "FROM arxiv_chunks\n",
    "WHERE paper_id = '{paper_id}'\n",
    "ORDER BY chunk_id\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# üîç Load into a DataFrame\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# üñºÔ∏è Display nicely\n",
    "pd.set_option('display.max_colwidth', 200)  # So chunk_data isn't truncated badly\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac2130-591f-48cc-b9f6-df9f202f6433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
