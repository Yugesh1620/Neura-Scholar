{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2547cd-7f2f-439a-a704-2ec43aa549c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container \n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d213c273-53cd-4730-b31d-d71466f736c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.12/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from langdetect) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e86cc28-4ccc-4161-8cc0-a4aa834eb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002bc91a-061e-45b1-97a3-dcbd31e2bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Path: /home/jovyan/work/data-pipeline-files/metadata-v5/arxiv-metadata-oai.json\n",
      "Output Path: /home/jovyan/work/arxiv_cleaned_v2.csv\n",
      "PDF Filenames TXT: /home/jovyan/work/data-pipeline-files/all_files_list.txt\n"
     ]
    }
   ],
   "source": [
    "meta_data_dir = os.getenv(\"METADATA_DIR\", \"/mnt/meta-data\")\n",
    "\n",
    "input_path = os.path.join('/home/jovyan/work/data-pipeline-files/metadata-v5/', 'arxiv-metadata-oai.json')\n",
    "output_path = os.path.join('/home/jovyan/work/', 'arxiv_cleaned_v2.csv')\n",
    "pdf_filenames_txt = os.path.join('/home/jovyan/work/data-pipeline-files', 'all_files_list.txt')\n",
    "\n",
    "print(\"Input Path:\", input_path)\n",
    "print(\"Output Path:\", output_path)\n",
    "print(\"PDF Filenames TXT:\", pdf_filenames_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd325fab-6549-4a06-8862-88d81f2a28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'data-pipeline-files', '.git', 'System Diagram.png', 'README.md', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/home/jovyan/work/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c535e33-2f91-408c-ba0d-ea412d08d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['store_text_to_chunks.ipynb', 'docker-compose-meta-data-db.yaml', 'venv', 'docker-compose-meta-data-db-jupyter.yaml', 'clear_metadata.ipynb', 'data-preprocessing.ipynb', 'rearrage_folders.sh', 'tar_files_list.txt', 'pdf-to-text-from-folder.py', 'pull-data-script.sh', 'read_me_setup_dbs.md', 'metadata-v5', 'create-tar-files-list.sh', 'docker-compose-download-raw-pdfs.yaml', 'docker-compose-pdf-to-text.yaml', 'folders_list.txt', 'download-dependensies.sh', 'process-meta-data.ipynb', 'create_text_files_list.sh', 'all_files_list.txt', '.ipynb_checkpoints', 'process_tar_files.sh']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/home/jovyan/work/data-pipeline-files'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc09ea04-2e13-46c7-81fd-84d8ab7f76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meta-data', 'metadata', 'raw-data', 'text-files-data']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(meta_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57427b14-32c9-4e80-bafc-ea7e51f902cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ffff112-0fda-4bda-a55e-75130a7ad984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latest_version_info(versions):\n",
    "    if not versions or not isinstance(versions, list):\n",
    "        return \"\", \"\"\n",
    "    \n",
    "    # Assume latest is the last string in the list\n",
    "    latest_version = versions[-1]\n",
    "    \n",
    "    if isinstance(latest_version, str):\n",
    "        return latest_version, \"\"  # No created date info available\n",
    "    elif isinstance(latest_version, dict):\n",
    "        return latest_version.get('version', ''), latest_version.get('created', '')\n",
    "    else:\n",
    "        return \"\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b823679-f758-453a-be68-48b758f20056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_authors(authors_parsed):\n",
    "    if not authors_parsed or not isinstance(authors_parsed, list):\n",
    "        return \"\"\n",
    "    return \", \".join(\" \".join(filter(None, author)) for author in authors_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407facb1-0336-43a2-8111-145f36dc78e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 449322 PDF filenames.\n"
     ]
    }
   ],
   "source": [
    "pdf_filenames_set = set()\n",
    "with open(pdf_filenames_txt, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        filename = line.strip()\n",
    "        if filename:\n",
    "            pdf_filenames_set.add(filename)\n",
    "\n",
    "print(f\"Loaded {len(pdf_filenames_set)} PDF filenames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6222fa88-226b-4361-a662-70c5003c22e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in metadata file: 3360984\n"
     ]
    }
   ],
   "source": [
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Total lines in metadata file: {total_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b763ba25-abbf-440a-8ae0-d13d74a39179",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_count = 0\n",
    "fieldnames_written = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ed8785-98e6-4f6a-ad79-a61920dc758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"0704.0001\",\n",
      "  \"submitter\": \"Pavel Nadolsky\",\n",
      "  \"authors\": \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
      "  \"title\": \"Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies\",\n",
      "  \"comments\": \"37 pages, 15 figures; published version\",\n",
      "  \"journal-ref\": \"Phys.Rev.D76:013009,2007\",\n",
      "  \"doi\": \"10.1103/PhysRevD.76.013009\",\n",
      "  \"abstract\": \"  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n\",\n",
      "  \"report-no\": \"ANL-HEP-PR-07-12\",\n",
      "  \"categories\": [\n",
      "    \"hep-ph\"\n",
      "  ],\n",
      "  \"versions\": [\n",
      "    \"v1\",\n",
      "    \"v2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    for i in range(1):\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break  # End of file reached before 5 lines\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            print(json.dumps(record, indent=2))  # Pretty-print each record\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"⚠️ Line {i+1}: Invalid JSON, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a055841-0756-4b10-a880-62b28082c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stored: 23384:   1%|          | 23531/3360984 [01:58<4:16:36, 216.77it/s]"
     ]
    }
   ],
   "source": [
    "with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = None\n",
    "\n",
    "    # Count total lines for progress bar\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "\n",
    "    progress = tqdm(infile, total=total_lines, desc=\"Stored: 0\", dynamic_ncols=True)\n",
    "\n",
    "    for line in progress:\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            text = f\"{record.get('title', '')} {record.get('abstract', '')}\".strip()\n",
    "\n",
    "            # Extract version info\n",
    "            latest_version, latest_created = extract_latest_version_info(record.get(\"versions\", []))\n",
    "            pdf_filename = f\"{record['id']}{latest_version}.txt\"\n",
    "\n",
    "            # Check filename existence and English language\n",
    "            if pdf_filename in pdf_filenames_set and text and is_english(text):\n",
    "                record[\"latest_version\"] = latest_version\n",
    "                # record[\"latest_created\"] = latest_created  # Uncomment if needed\n",
    "                record[\"txt_filename\"] = pdf_filename\n",
    "                record[\"created_yymm\"] = pdf_filename.split('.')[0]  # You may want a more precise format\n",
    "                record.pop(\"versions\", None)\n",
    "\n",
    "                if writer is None:\n",
    "                    fieldnames = list(record.keys())\n",
    "                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    fieldnames_written = True\n",
    "\n",
    "                writer.writerow(record)\n",
    "                english_count += 1\n",
    "                progress.set_description(f\"Stored: {english_count}\")\n",
    "\n",
    "        except (json.JSONDecodeError, UnicodeEncodeError, KeyError):\n",
    "            continue  # Skip corrupted lines or missing keys\n",
    "\n",
    "print(f\"\\n✅ English records written: {english_count}\")\n",
    "print(f\"📁 Cleaned data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9877954-2e21-4907-8543-576b55571f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
