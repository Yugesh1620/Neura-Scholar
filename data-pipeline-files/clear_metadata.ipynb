{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca2547cd-7f2f-439a-a704-2ec43aa549c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container \n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d213c273-53cd-4730-b31d-d71466f736c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.12/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from langdetect) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e86cc28-4ccc-4161-8cc0-a4aa834eb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "002bc91a-061e-45b1-97a3-dcbd31e2bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Path: /mnt/metadata/arxiv-metadata-oai-snapshot.json\n",
      "Output Path: /home/jovyan/work/arxiv_cleaned_v3.csv\n",
      "PDF Filenames TXT: /mnt/metadata/all_files_list.txt\n"
     ]
    }
   ],
   "source": [
    "meta_data_dir = os.getenv(\"METADATA_DIR\", \"/mnt/metadata\")\n",
    "\n",
    "input_path = os.path.join(meta_data_dir, 'arxiv-metadata-oai-snapshot.json')\n",
    "output_path = os.path.join('/home/jovyan/work/', 'arxiv_cleaned_v3.csv')\n",
    "pdf_filenames_txt = os.path.join(meta_data_dir, 'all_files_list.txt')\n",
    "\n",
    "print(\"Input Path:\", input_path)\n",
    "print(\"Output Path:\", output_path)\n",
    "print(\"PDF Filenames TXT:\", pdf_filenames_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd325fab-6549-4a06-8862-88d81f2a28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_files_list.txt', 'arxiv-metadata-oai-snapshot.json', 'authors-parsed.json', 'internal-citations.json']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(meta_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57427b14-32c9-4e80-bafc-ea7e51f902cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ffff112-0fda-4bda-a55e-75130a7ad984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latest_version_info(versions):\n",
    "    if not versions or not isinstance(versions, list):\n",
    "        return \"\", \"\"\n",
    "    \n",
    "    # Assume latest is the last string in the list\n",
    "    latest_version = versions[-1]\n",
    "    \n",
    "    if isinstance(latest_version, str):\n",
    "        return latest_version, \"\"  # No created date info available\n",
    "    elif isinstance(latest_version, dict):\n",
    "        return latest_version.get('version', ''), latest_version.get('created', '')\n",
    "    else:\n",
    "        return \"\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b823679-f758-453a-be68-48b758f20056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_authors(authors_parsed):\n",
    "    if not authors_parsed or not isinstance(authors_parsed, list):\n",
    "        return \"\"\n",
    "    return \", \".join(\" \".join(filter(None, author)) for author in authors_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "407facb1-0336-43a2-8111-145f36dc78e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 364068 PDF filenames.\n"
     ]
    }
   ],
   "source": [
    "pdf_filenames_set = set()\n",
    "with open(pdf_filenames_txt, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        filename = line.strip()\n",
    "        if filename:\n",
    "            pdf_filenames_set.add(filename)\n",
    "\n",
    "print(f\"Loaded {len(pdf_filenames_set)} PDF filenames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6222fa88-226b-4361-a662-70c5003c22e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in metadata file: 2720631\n"
     ]
    }
   ],
   "source": [
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Total lines in metadata file: {total_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b763ba25-abbf-440a-8ae0-d13d74a39179",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_count = 0\n",
    "fieldnames_written = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2ed8785-98e6-4f6a-ad79-a61920dc758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"0704.0001\",\n",
      "  \"submitter\": \"Pavel Nadolsky\",\n",
      "  \"authors\": \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
      "  \"title\": \"Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies\",\n",
      "  \"comments\": \"37 pages, 15 figures; published version\",\n",
      "  \"journal-ref\": \"Phys.Rev.D76:013009,2007\",\n",
      "  \"doi\": \"10.1103/PhysRevD.76.013009\",\n",
      "  \"report-no\": \"ANL-HEP-PR-07-12\",\n",
      "  \"categories\": \"hep-ph\",\n",
      "  \"license\": null,\n",
      "  \"abstract\": \"  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n\",\n",
      "  \"versions\": [\n",
      "    {\n",
      "      \"version\": \"v1\",\n",
      "      \"created\": \"Mon, 2 Apr 2007 19:18:42 GMT\"\n",
      "    },\n",
      "    {\n",
      "      \"version\": \"v2\",\n",
      "      \"created\": \"Tue, 24 Jul 2007 20:10:27 GMT\"\n",
      "    }\n",
      "  ],\n",
      "  \"update_date\": \"2008-11-26\",\n",
      "  \"authors_parsed\": [\n",
      "    [\n",
      "      \"Bal\\u00e1zs\",\n",
      "      \"C.\",\n",
      "      \"\"\n",
      "    ],\n",
      "    [\n",
      "      \"Berger\",\n",
      "      \"E. L.\",\n",
      "      \"\"\n",
      "    ],\n",
      "    [\n",
      "      \"Nadolsky\",\n",
      "      \"P. M.\",\n",
      "      \"\"\n",
      "    ],\n",
      "    [\n",
      "      \"Yuan\",\n",
      "      \"C. -P.\",\n",
      "      \"\"\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    for i in range(1):\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break  # End of file reached before 5 lines\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            print(json.dumps(record, indent=2))  # Pretty-print each record\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"‚ö†Ô∏è Line {i+1}: Invalid JSON, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a055841-0756-4b10-a880-62b28082c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stored: 227494: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2720631/2720631 [33:47<00:00, 1341.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ English records written: 227494\n",
      "üìÅ Saved cleaned data to: /home/jovyan/work/arxiv_cleaned_v3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = None\n",
    "\n",
    "    progress = tqdm(infile, total=total_lines, desc=f\"Stored: {english_count}\", dynamic_ncols=True)\n",
    "\n",
    "    for line in progress:\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            text = f\"{record.get('title', '')} {record.get('abstract', '')}\".strip()\n",
    "\n",
    "            # Get version info FIRST to construct the PDF filename\n",
    "            latest_version, latest_created = extract_latest_version_info(record.get(\"versions\", []))\n",
    "            pdf_filename = f\"{record['id']}{latest_version}.txt\"\n",
    "\n",
    "            # Only keep if the file is in your allowed PDF names\n",
    "            if pdf_filename in pdf_filenames_set:\n",
    "                # Now check if it's English\n",
    "                if text and is_english(text):\n",
    "                # ‚úÖ Process the matching record\n",
    "                    record[\"latest_version\"] = latest_version\n",
    "                    record[\"latest_created\"] = latest_created\n",
    "                    record[\"pdf_filename\"] = pdf_filename\n",
    "                    record.pop(\"versions\", None)\n",
    "        \n",
    "                    if writer is None:\n",
    "                        fieldnames = list(record.keys())\n",
    "                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                        writer.writeheader()\n",
    "                        fieldnames_written = True\n",
    "        \n",
    "                    writer.writerow(record)\n",
    "                    english_count += 1\n",
    "        \n",
    "                    # üîÑ Update progress bar description\n",
    "                    progress.set_description(f\"Stored: {english_count}\")\n",
    "\n",
    "        except (json.JSONDecodeError, UnicodeEncodeError, KeyError):\n",
    "            continue  # Skip broken lines or missing keys\n",
    "\n",
    "print(f\"\\n‚úÖ English records written: {english_count}\")\n",
    "print(f\"üìÅ Saved cleaned data to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16071d59-58bf-4e7d-bc98-2a2754eef8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9877954-2e21-4907-8543-576b55571f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
